"""
Assistant IA utilisant OpenAI GPT-3.5-Turbo
Service pour gÃ©rer les conversations avec contexte des donnÃ©es pÃ©dagogiques
"""
import os
from openai import OpenAI
from typing import List, Dict, Optional
import pandas as pd

class AssistantIA:
    def __init__(self, df: pd.DataFrame = None):
        """
        Initialise l'assistant IA avec la clÃ© OpenAI
        """
        api_key = os.getenv('OPENAI_API_KEY')
        if not api_key:
            raise ValueError("OPENAI_API_KEY non trouvÃ©e dans les variables d'environnement")
        
        self.client = OpenAI(api_key=api_key)
        self.df = df
        self.model = "gpt-3.5-turbo"  # Ã‰conomique et rapide
        
        # System prompt optimisÃ© pour le contexte pÃ©dagogique
        self.system_prompt = """Tu es un assistant pÃ©dagogique expert pour un systÃ¨me de recommandation de soutien 
pÃ©dagogique dans les universitÃ©s marocaines.

TON RÃ”LE:
- Aider les enseignants et tuteurs Ã  comprendre les prÃ©dictions du systÃ¨me ML
- Expliquer de maniÃ¨re claire pourquoi un Ã©tudiant est Ã  risque
- Proposer des actions concrÃ¨tes et personnalisÃ©es
- RÃ©pondre aux questions sur les modules, filiÃ¨res et statistiques

STYLE DE RÃ‰PONSE:
- Professionnel mais accessible
- Concis et actionnable (maximum 3-4 paragraphes)
- Utilise des emojis pour rendre les rÃ©ponses plus engageantes
- Structure tes rÃ©ponses avec des points clÃ©s
- Toujours en franÃ§ais

DONNÃ‰ES DISPONIBLES:
Le systÃ¨me contient des donnÃ©es rÃ©elles sur:
- Profils Ã©tudiants (notes, moyennes, historique acadÃ©mique)
- PrÃ©dictions ML (probabilitÃ©s de risque, profils d'apprentissage)
- Statistiques modules (taux d'Ã©chec, difficultÃ©s, moyennes)
- Recommandations automatiques gÃ©nÃ©rÃ©es par IA

IMPORTANT:
- Base tes rÃ©ponses sur les donnÃ©es fournies dans le contexte
- Si les donnÃ©es ne sont pas disponibles, dis-le clairement
- Sois encourageant et propose toujours des solutions"""

    def get_context_from_data(self, message: str) -> str:
        """
        Extrait du contexte pertinent depuis les donnÃ©es selon la question
        """
        if self.df is None:
            return ""
        
        context_parts = []
        message_lower = message.lower()
        
        # Si mention d'un code Ã©tudiant (chiffres)
        import re
        student_codes = re.findall(r'\b\d{5,}\b', message)
        if student_codes:
            for code in student_codes[:1]:  # Limiter Ã  1 pour Ã©viter trop de contexte
                student_data = self.df[self.df['ID'].astype(str) == code]
                if len(student_data) > 0:
                    moyenne = student_data['Note_sur_20'].mean() if 'Note_sur_20' in student_data.columns else 0
                    nb_modules = len(student_data)
                    filiere = student_data['Filiere'].iloc[0] if 'Filiere' in student_data.columns else 'N/A'
                    context_parts.append(f"Ã‰tudiant {code}: FiliÃ¨re {filiere}, Moyenne {moyenne:.1f}/20, {nb_modules} modules")
        
        # Statistiques gÃ©nÃ©rales si demandÃ©es
        if any(word in message_lower for word in ['statistique', 'combien', 'nombre', 'total']):
            total_students = self.df['ID'].nunique() if 'ID' in self.df.columns else 0
            context_parts.append(f"Total Ã©tudiants dans le systÃ¨me: {total_students}")
        
        # Informations sur les modules
        if 'module' in message_lower and 'Module' in self.df.columns:
            modules = self.df['Module'].unique()[:5]  # Top 5 modules
            context_parts.append(f"Modules disponibles: {', '.join(modules)}")
        
        return "\n\n".join(context_parts) if context_parts else ""

    def chat(self, 
             message: str, 
             history: List[Dict[str, str]] = None,
             context: Optional[str] = None) -> Dict:
        """
        Envoie un message Ã  l'assistant et retourne la rÃ©ponse
        
        Args:
            message: Message de l'utilisateur
            history: Historique de conversation (liste de {role, content})
            context: Contexte additionnel (donnÃ©es Ã©tudiant, stats, etc.)
        
        Returns:
            Dict avec 'response', 'tokens_used', 'cost'
        """
        try:
            # Construire l'historique des messages
            messages = [{"role": "system", "content": self.system_prompt}]
            
            # Ajouter contexte des donnÃ©es si disponible
            data_context = self.get_context_from_data(message)
            if data_context:
                messages.append({
                    "role": "system", 
                    "content": f"DonnÃ©es pertinentes:\n{data_context}"
                })
            
            # Ajouter contexte supplÃ©mentaire si fourni
            if context:
                messages.append({
                    "role": "system",
                    "content": f"Contexte additionnel:\n{context}"
                })
            
            # Ajouter historique de conversation
            if history:
                messages.extend(history[-10:])  # Garder les 10 derniers messages max
            
            # Ajouter le message actuel
            messages.append({"role": "user", "content": message})
            
            # Appel Ã  l'API OpenAI
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=0.7,
                max_tokens=500,  # Limite pour Ã©conomiser
            )
            
            # Extraire la rÃ©ponse
            assistant_message = response.choices[0].message.content
            
            # Calculer le coÃ»t (GPT-3.5-turbo: $0.50/1M input, $1.50/1M output)
            input_tokens = response.usage.prompt_tokens
            output_tokens = response.usage.completion_tokens
            total_tokens = response.usage.total_tokens
            
            cost = (input_tokens * 0.50 / 1_000_000) + (output_tokens * 1.50 / 1_000_000)
            
            return {
                'response': assistant_message,
                'tokens_used': total_tokens,
                'cost': cost,
                'success': True
            }
            
        except Exception as e:
            return {
                'response': f"DÃ©solÃ©, une erreur s'est produite: {str(e)}",
                'tokens_used': 0,
                'cost': 0,
                'success': False,
                'error': str(e)
            }

    def get_welcome_message(self) -> str:
        """Message de bienvenue de l'assistant"""
        return """ğŸ‘‹ Bonjour ! Je suis votre assistant pÃ©dagogique IA.

Je peux vous aider Ã  :
â€¢ ğŸ“Š Comprendre les prÃ©dictions du systÃ¨me ML
â€¢ ğŸ‘¨â€ğŸ“ Analyser les profils desÃ©tudiants
â€¢ ğŸ“ˆ Expliquer les statistiques des modules
â€¢ ğŸ’¡ Proposer des actions de soutien personnalisÃ©es

Comment puis-je vous aider aujourd'hui ?"""
