"""
Script de test pour v√©rifier que le mod√®le ML fonctionne correctement
"""
import joblib
import pandas as pd
import numpy as np
from pathlib import Path

print("=" * 70)
print("TEST DU MOD√àLE ML - Syst√®me de Soutien P√©dagogique")
print("=" * 70)

# 1. V√©rifier existence du mod√®le
print("\n1. V√âRIFICATION DU FICHIER MOD√àLE")
print("-" * 70)
model_path = Path("output_projet4/model_soutien_pedagogique.joblib")
if model_path.exists():
    print(f"‚úÖ Mod√®le trouv√©: {model_path}")
    print(f"   Taille: {model_path.stat().st_size / 1024 / 1024:.2f} MB")
else:
    print(f"‚ùå Mod√®le NOT FOUND: {model_path}")
    exit(1)

# 2. Charger le mod√®le
print("\n2. CHARGEMENT DU MOD√àLE")
print("-" * 70)
try:
    model_data = joblib.load(model_path)
    print("‚úÖ Mod√®le charg√© avec succ√®s")
    print(f"   Type: {type(model_data)}")
    
    if isinstance(model_data, dict):
        print(f"   Cl√©s disponibles: {list(model_data.keys())}")
    else:
        print("   ‚ö†Ô∏è Le mod√®le n'est pas un dictionnaire")
except Exception as e:
    print(f"‚ùå Erreur de chargement: {e}")
    exit(1)

# 3. V√©rifier les composants du mod√®le
print("\n3. COMPOSANTS DU MOD√àLE")
print("-" * 70)
required_keys = ['model', 'scaler', 'feature_columns', 'le_filiere', 'kmeans', 'profil_mapping']
for key in required_keys:
    if key in model_data:
        print(f"‚úÖ {key}: {type(model_data[key])}")
    else:
        print(f"‚ùå {key}: MANQUANT")

# 4. V√©rifier les features
print("\n4. FEATURES DU MOD√àLE")
print("-" * 70)
if 'feature_columns' in model_data:
    features = model_data['feature_columns']
    print(f"‚úÖ Nombre de features: {len(features)}")
    print(f"   Premi√®res features: {features[:5]}")
    print(f"   Derni√®res features: {features[-5:]}")
else:
    print("‚ùå feature_columns manquant")

# 5. Tester une pr√©diction
print("\n5. TEST DE PR√âDICTION")
print("-" * 70)
try:
    # Cr√©er des donn√©es de test
    calibrated_model = model_data['model']
    scaler = model_data['scaler']
    feature_columns = model_data['feature_columns']
    
    # Cr√©er un vecteur de features de test (moyennes r√©alistes)
    test_features = {col: 50.0 for col in feature_columns}
    test_features['Note_sur_20'] = 10.5
    test_features['Total'] = 52.5
    test_features['Practical'] = 21.0
    test_features['Theoretical'] = 31.5
    
    X_test = pd.DataFrame([test_features])[feature_columns]
    X_test_scaled = scaler.transform(X_test)
    
    # Faire une pr√©diction
    prediction = calibrated_model.predict(X_test_scaled)[0]
    proba = calibrated_model.predict_proba(X_test_scaled)[0]
    
    print("‚úÖ Pr√©diction r√©ussie!")
    print(f"   R√©sultat: {'BESOIN SOUTIEN' if prediction == 1 else 'PAS DE SOUTIEN'}")
    print(f"   Probabilit√© classe 0: {proba[0]:.3f}")
    print(f"   Probabilit√© classe 1: {proba[1]:.3f}")
    
except Exception as e:
    print(f"‚ùå Erreur de pr√©diction: {e}")
    import traceback
    traceback.print_exc()

# 6. V√©rifier le clustering
print("\n6. TEST DE CLUSTERING")
print("-" * 70)
try:
    kmeans = model_data['kmeans']
    profil_mapping = model_data['profil_mapping']
    
    # Test cluster
    cluster = kmeans.predict(X_test_scaled)[0]
    profil = profil_mapping.get(cluster, 'Inconnu')
    
    print("‚úÖ Clustering r√©ussi!")
    print(f"   Cluster: {cluster}")
    print(f"   Profil: {profil}")
    print(f"   Mapping complet: {profil_mapping}")
    
except Exception as e:
    print(f"‚ùå Erreur de clustering: {e}")

# 7. Charger les donn√©es et tester avec un vrai √©tudiant
print("\n7. TEST AVEC DONN√âES R√âELLES")
print("-" * 70)
try:
    df1 = pd.read_csv("raw/1- one_clean.csv", encoding='utf-8')
    df2 = pd.read_csv("raw/2- two_clean.csv", encoding='utf-8')
    df = pd.concat([df1, df2], ignore_index=True)
    
    # Nettoyage
    df['ID'] = df['ID'].astype(str)
    df = df[~df['ID'].isin(['Unknown', 'unknown', 'nan', 'None', ''])].copy()
    df = df.rename(columns={'Major': 'Filiere', 'Subject': 'Module'})
    df['Note_sur_20'] = df['Total'] / 5 if 'Total' in df.columns else 0
    
    print(f"‚úÖ Donn√©es charg√©es: {len(df):,} enregistrements")
    
    # Tester avec le premier √©tudiant
    student_ids = df['ID'].unique()[:5]
    print(f"   Codes √©tudiants de test: {student_ids}")
    
    test_id = student_ids[0]
    student_data = df[df['ID'] == test_id].copy()
    
    print(f"\n   Test avec √©tudiant: {test_id}")
    print(f"   Fili√®re: {student_data['Filiere'].iloc[0] if 'Filiere' in student_data.columns else 'N/A'}")
    print(f"   Nombre de modules: {len(student_data)}")
    print(f"   Moyenne: {student_data['Note_sur_20'].mean():.2f}/20" if 'Note_sur_20' in student_data.columns else "   Moyenne: N/A")
    
except Exception as e:
    print(f"‚ö†Ô∏è Impossible de tester avec donn√©es r√©elles: {e}")

# 8. R√©sum√©
print("\n" + "=" * 70)
print("R√âSUM√â DU TEST")
print("=" * 70)
print("‚úÖ Mod√®le existe et se charge correctement")
print("‚úÖ Tous les composants n√©cessaires pr√©sents")
print(f"‚úÖ {len(features)} features configur√©es")
print("‚úÖ Pr√©dictions fonctionnent")
print("‚úÖ Clustering fonctionne")
print("\nüéâ LE MOD√àLE ML FONCTIONNE CORRECTEMENT !")
print("=" * 70)
