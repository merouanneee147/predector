"""
ğŸ”µ Projet 4 : SystÃ¨me de Recommandation Intelligente de Soutien PÃ©dagogique
==============================================================================
ğŸ‡²ğŸ‡¦ AdaptÃ© pour les Ã‰tablissements d'Enseignement SupÃ©rieur Marocains
   (UniversitÃ©s, ENSA, ENSAM, FST, Ã‰coles d'IngÃ©nieurs)

Objectif: Identifier automatiquement les combinaisons Ã‰tudiant-Module nÃ©cessitant 
une intervention pÃ©dagogique pour optimiser l'allocation des ressources de tutorat
et de soutien universitaire.

Contexte Marocain:
- SystÃ¨me LMD (Licence-Master-Doctorat)
- Validation par modules et semestres
- Note de passage: 10/20 (ou 12/20 selon les filiÃ¨res)
- Rattrapages et sessions de rattrapage

Variable Cible: Needs_Support = 1 si:
  - Statut = Non ValidÃ© / AjournÃ© / Rattrapage
  - Note < 10/20 (seuil de validation)
  - Patterns d'absentÃ©isme

Algorithmes:
- Collaborative Filtering (similaritÃ© entre Ã©tudiants)
- XGBoost Classifier avec calibration de probabilitÃ©s
- K-Means Clustering + Classification
- Scoring de risque pour priorisation
"""

import pandas as pd
import numpy as np
import warnings
from pathlib import Path

# Machine Learning
from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.cluster import KMeans, DBSCAN
from sklearn.neighbors import NearestNeighbors
from sklearn.calibration import CalibratedClassifierCV
from sklearn.metrics import (classification_report, confusion_matrix, 
                            roc_auc_score, precision_recall_curve, 
                            average_precision_score, f1_score)
from sklearn.ensemble import RandomForestClassifier
import xgboost as xgb

# Visualization
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats

warnings.filterwarnings('ignore')
plt.style.use('seaborn-v0_8-whitegrid')

# Configuration
RAW_PATH = Path("raw")
OUTPUT_PATH = Path("output_projet4")
OUTPUT_PATH.mkdir(exist_ok=True)

print("=" * 80)
print("ğŸ”µ PROJET 4: SYSTÃˆME DE RECOMMANDATION INTELLIGENTE DE SOUTIEN PÃ‰DAGOGIQUE")
print("ğŸ‡²ğŸ‡¦ AdaptÃ© pour les Ã‰tablissements d'Enseignement SupÃ©rieur Marocains")
print("=" * 80)

# =============================================================================
# 1. CHARGEMENT ET PRÃ‰PARATION DES DONNÃ‰ES
# =============================================================================
print("\n" + "=" * 80)
print("ğŸ“Š Ã‰TAPE 1: CHARGEMENT ET PRÃ‰PARATION DES DONNÃ‰ES")
print("=" * 80)

# Charger les deux fichiers
df1 = pd.read_csv(RAW_PATH / "1- one_clean.csv")
df2 = pd.read_csv(RAW_PATH / "2- two_clean.csv")

# Combiner les datasets
df = pd.concat([df1, df2], ignore_index=True)

print(f"\nğŸ“ DonnÃ©es chargÃ©es:")
print(f"   â€¢ Fichier 1: {len(df1):,} enregistrements")
print(f"   â€¢ Fichier 2: {len(df2):,} enregistrements")
print(f"   â€¢ Total combinÃ©: {len(df):,} enregistrements")

# Nettoyer les donnÃ©es
print("\nğŸ”§ Nettoyage des donnÃ©es...")

# Taille avant nettoyage
taille_avant = len(df)

# Supprimer les lignes avec ID null ou Unknown
df['ID'] = df['ID'].astype(str)
df = df[~df['ID'].isin(['Unknown', 'unknown', 'nan', 'None', ''])].copy()
df = df[df['ID'].notna()].copy()

# Supprimer les lignes avec Major/FiliÃ¨re Unknown
df = df[~df['Major'].astype(str).str.lower().str.contains('unknown', na=False)].copy()

# Supprimer les lignes avec Subject/Module Unknown
df = df[~df['Subject'].astype(str).str.lower().str.contains('unknown', na=False)].copy()

# Supprimer les lignes avec Total null (notes manquantes)
df = df[df['Total'].notna() | (df['Practical'].notna() & df['Theoretical'].notna())].copy()

print(f"   â€¢ Enregistrements supprimÃ©s (Unknown/null): {taille_avant - len(df):,}")

# Renommer les colonnes pour le contexte marocain
# Major -> FiliÃ¨re, Subject -> Module, MajorYear -> AnnÃ©e
df = df.rename(columns={
    'Major': 'Filiere',
    'Subject': 'Module', 
    'MajorYear': 'Annee',
    'OfficalYear': 'AnneUniversitaire'
})

# Convertir les colonnes numÃ©riques
df['Practical'] = pd.to_numeric(df['Practical'], errors='coerce').fillna(0)
df['Theoretical'] = pd.to_numeric(df['Theoretical'], errors='coerce').fillna(0)
df['Total'] = pd.to_numeric(df['Total'], errors='coerce')

# Calculer Total si manquant
df['Total'] = df['Total'].fillna(df['Practical'] + df['Theoretical'])

# Convertir les notes sur 20 (systÃ¨me marocain) si nÃ©cessaire
# Si les notes sont sur 100, les convertir sur 20
if df['Total'].max() > 20:
    df['Note_sur_20'] = df['Total'] / 5  # Conversion 100 -> 20
else:
    df['Note_sur_20'] = df['Total']

# Nettoyer AnnÃ©e d'Ã©tudes
df['Annee'] = pd.to_numeric(df['Annee'], errors='coerce').fillna(1).astype(int)

# Nettoyer Semestre
df['Semester'] = pd.to_numeric(df['Semester'], errors='coerce').fillna(1).astype(int)

print(f"   â€¢ AprÃ¨s nettoyage: {len(df):,} enregistrements")
print(f"   â€¢ Ã‰tudiants uniques: {df['ID'].nunique():,}")
print(f"   â€¢ Modules uniques: {df['Module'].nunique()}")
print(f"   â€¢ FiliÃ¨res: {df['Filiere'].nunique()}")

# Mapper les statuts vers le systÃ¨me marocain
status_mapping = {
    'Pass': 'ValidÃ©',
    'Fail': 'Non_ValidÃ©',
    'Absent': 'Absent',
    'Debarred': 'Exclu',
    'Withdrawal': 'Abandon',
    'Withhold': 'En_Attente',
    'Exempt': 'DispensÃ©'
}
df['Statut_MA'] = df['Status'].map(status_mapping).fillna(df['Status'])

# Afficher la distribution des Statuts
print(f"\nğŸ“Š Distribution des Statuts (SystÃ¨me Marocain):")
status_counts = df['Statut_MA'].value_counts()
for status, count in status_counts.items():
    pct = count / len(df) * 100
    print(f"   â€¢ {status}: {count:,} ({pct:.1f}%)")

# =============================================================================
# 2. CRÃ‰ATION DE LA VARIABLE CIBLE (Needs_Support) - Contexte Marocain
# =============================================================================
print("\n" + "=" * 80)
print("ğŸ¯ Ã‰TAPE 2: CRÃ‰ATION DE LA VARIABLE CIBLE (SystÃ¨me Marocain)")
print("=" * 80)

# Seuil de validation au Maroc (gÃ©nÃ©ralement 10/20 ou 12/20)
SEUIL_VALIDATION = 10  # Note minimale pour valider un module

# DÃ©finir les statuts nÃ©cessitant un soutien
statuts_problematiques = ['Non_ValidÃ©', 'Absent', 'Exclu', 'Abandon', 'En_Attente', 'Fail', 'Debarred', 'Withdrawal', 'Withhold']

def needs_support_ma(row):
    """
    DÃ©termine si un Ã©tudiant marocain a besoin de soutien pour un module.
    CritÃ¨res adaptÃ©s au systÃ¨me universitaire marocain:
    1. Statut = Non ValidÃ© / AjournÃ©
    2. Note < 10/20 (seuil de validation standard)
    3. Patterns d'absentÃ©isme ou exclusion
    4. Risque de redoublement
    """
    # CritÃ¨re 1: Non validation explicite
    if row['Status'] == 'Fail' or row['Statut_MA'] == 'Non_ValidÃ©':
        return 1
    
    # CritÃ¨re 2: Note insuffisante (< 10/20)
    if pd.notna(row['Note_sur_20']) and row['Note_sur_20'] > 0 and row['Note_sur_20'] < SEUIL_VALIDATION:
        return 1
    
    # CritÃ¨re 3: Note originale faible (si sur 100, < 50)
    if pd.notna(row['Total']) and row['Total'] > 0 and row['Total'] < 50:
        return 1
    
    # CritÃ¨re 4: Patterns problÃ©matiques (absentÃ©isme, exclusion, abandon)
    if row['Statut_MA'] in ['Absent', 'Exclu', 'Abandon']:
        return 1
    
    # CritÃ¨re 5: En attente (gÃ©nÃ©ralement problÃ¨me administratif ou acadÃ©mique)
    if row['Statut_MA'] == 'En_Attente':
        return 1
    
    return 0

df['Needs_Support'] = df.apply(needs_support_ma, axis=1)

# Classification selon le systÃ¨me marocain
def classification_ma(note):
    """Classification des notes selon le barÃ¨me marocain"""
    if pd.isna(note) or note == 0:
        return 'Non_Ã‰valuÃ©'
    elif note >= 16:
        return 'TrÃ¨s_Bien'
    elif note >= 14:
        return 'Bien'
    elif note >= 12:
        return 'Assez_Bien'
    elif note >= 10:
        return 'Passable'
    else:
        return 'Non_ValidÃ©'

df['Mention'] = df['Note_sur_20'].apply(classification_ma)

print(f"\nğŸ¯ Variable Cible crÃ©Ã©e: Needs_Support (Besoin de Soutien)")
print(f"   â€¢ Seuil de validation: {SEUIL_VALIDATION}/20")
print(f"   â€¢ Ã‰tudiants nÃ©cessitant un soutien: {df['Needs_Support'].sum():,} ({df['Needs_Support'].mean()*100:.1f}%)")
print(f"   â€¢ Ã‰tudiants sans besoin identifiÃ©: {(1-df['Needs_Support']).sum():,} ({(1-df['Needs_Support'].mean())*100:.1f}%)")

print(f"\nğŸ“Š RÃ©partition par Mention:")
mention_counts = df['Mention'].value_counts()
for mention in ['TrÃ¨s_Bien', 'Bien', 'Assez_Bien', 'Passable', 'Non_ValidÃ©', 'Non_Ã‰valuÃ©']:
    if mention in mention_counts.index:
        count = mention_counts[mention]
        pct = count / len(df) * 100
        print(f"   â€¢ {mention}: {count:,} ({pct:.1f}%)")

# =============================================================================
# 3. FEATURE ENGINEERING AVANCÃ‰ - Contexte Universitaire Marocain
# =============================================================================
print("\n" + "=" * 80)
print("ğŸ”§ Ã‰TAPE 3: FEATURE ENGINEERING (Contexte Universitaire Marocain)")
print("=" * 80)

# 3.1 Performance du groupe de pairs (FiliÃ¨re + AnnÃ©e)
print("\nğŸ“ˆ 3.1 Calcul de la performance par promotion (FiliÃ¨re + AnnÃ©e)...")
peer_group = df.groupby(['Filiere', 'Annee']).agg({
    'Total': 'mean',
    'Note_sur_20': 'mean',
    'Practical': 'mean',
    'Theoretical': 'mean',
    'Needs_Support': 'mean'
}).reset_index()
peer_group.columns = ['Filiere', 'Annee', 'peer_group_avg_total', 'peer_group_avg_note20',
                      'peer_group_avg_practical', 'peer_group_avg_theoretical',
                      'peer_group_support_rate']

df = df.merge(peer_group, on=['Filiere', 'Annee'], how='left')

# Ã‰cart par rapport Ã  la promotion
df['deviation_from_peer'] = df['Total'] - df['peer_group_avg_total'].fillna(0)
df['deviation_note20'] = df['Note_sur_20'] - df['peer_group_avg_note20'].fillna(0)

# 3.2 Profil de Performance Ã‰tudiant (Historique)
print("ğŸ“ˆ 3.2 CrÃ©ation du profil de performance Ã©tudiant...")
student_profile = df.groupby('ID').agg({
    'Total': ['mean', 'std', 'min', 'max', 'count'],
    'Note_sur_20': ['mean', 'min'],
    'Practical': 'mean',
    'Theoretical': 'mean',
    'Needs_Support': ['sum', 'mean']
}).reset_index()
student_profile.columns = ['ID', 'student_avg_total', 'student_std_total', 
                           'student_min_total', 'student_max_total', 'student_module_count',
                           'student_avg_note20', 'student_min_note20',
                           'student_avg_practical', 'student_avg_theoretical',
                           'student_support_count', 'student_support_rate']
student_profile['student_std_total'] = student_profile['student_std_total'].fillna(0)

# Indicateur de risque de redoublement (plusieurs modules non validÃ©s)
student_profile['risque_redoublement'] = (student_profile['student_support_count'] >= 3).astype(int)

df = df.merge(student_profile, on='ID', how='left')

# 3.3 DifficultÃ© des Modules
print("ğŸ“ˆ 3.3 Calcul du score de difficultÃ© par module...")
module_stats = df.groupby('Module').agg({
    'Total': 'mean',
    'Note_sur_20': 'mean',
    'Needs_Support': 'mean',
    'ID': 'count'
}).reset_index()
module_stats.columns = ['Module', 'module_avg_total', 'module_avg_note20', 'module_taux_echec', 'module_effectif']

# Classifier les modules par difficultÃ©
def classifier_difficulte_module(taux_echec):
    if taux_echec >= 0.5:
        return 'TrÃ¨s_Difficile'
    elif taux_echec >= 0.3:
        return 'Difficile'
    elif taux_echec >= 0.15:
        return 'Moyen'
    else:
        return 'Accessible'

module_stats['difficulte_module'] = module_stats['module_taux_echec'].apply(classifier_difficulte_module)

df = df.merge(module_stats, on='Module', how='left')

# 3.4 Combinaisons FiliÃ¨re-Module Ã  Haut Risque
print("ğŸ“ˆ 3.4 Identification des combinaisons FiliÃ¨re-Module Ã  haut risque...")
filiere_module = df.groupby(['Filiere', 'Module']).agg({
    'Needs_Support': 'mean',
    'ID': 'count'
}).reset_index()
filiere_module.columns = ['Filiere', 'Module', 'combo_taux_echec', 'combo_effectif']
filiere_module['combo_haut_risque'] = (filiere_module['combo_taux_echec'] > 0.3).astype(int)

df = df.merge(filiere_module[['Filiere', 'Module', 'combo_taux_echec', 'combo_haut_risque']], 
              on=['Filiere', 'Module'], how='left')

# 3.5 Charge de Travail par Semestre
print("ğŸ“ˆ 3.5 Calcul de la charge de travail par semestre...")
workload = df.groupby(['ID', 'AnneUniversitaire', 'Semester'])['Module'].nunique().reset_index()
workload.columns = ['ID', 'AnneUniversitaire', 'Semester', 'charge_semestre']

df = df.merge(workload, on=['ID', 'AnneUniversitaire', 'Semester'], how='left')

# 3.6 Pattern d'AbsentÃ©isme
print("ğŸ“ˆ 3.6 DÃ©tection des patterns d'absentÃ©isme...")
absence_pattern = df.groupby('ID').apply(
    lambda x: (x['Statut_MA'].isin(['Absent', 'Exclu', 'Abandon'])).sum() / len(x)
).reset_index()
absence_pattern.columns = ['ID', 'taux_absenteisme']

df = df.merge(absence_pattern, on='ID', how='left')

# 3.7 Ã‰quilibre TP/Cours (Pratique vs ThÃ©orique)
print("ğŸ“ˆ 3.7 Calcul de l'Ã©quilibre TP/Cours...")
df['ratio_pratique'] = df['Practical'] / (df['Total'] + 1)
df['ecart_theorie_pratique'] = df['Theoretical'] - df['Practical']

# 3.8 CatÃ©gorie de Performance
print("ğŸ“ˆ 3.8 Analyse des tendances de performance...")
df['categorie_performance'] = pd.cut(df['Note_sur_20'], 
                                      bins=[-1, 6, 10, 12, 14, 20], 
                                      labels=['Critique', 'En_DifficultÃ©', 'Passable', 'Bien', 'Excellent'])

# 3.9 Profil de Force par CatÃ©gorie de Module (PÃ´les de compÃ©tences)
print("ğŸ“ˆ 3.9 Profil de force Ã©tudiant par pÃ´le de compÃ©tences...")

def categoriser_module(module):
    """CatÃ©gorisation des modules selon les pÃ´les de compÃ©tences marocains"""
    module_lower = str(module).lower()
    
    # Sciences fondamentales
    if any(word in module_lower for word in ['Ø±ÙŠØ§Ø¶ÙŠØ§Øª', 'math', 'Ø¬Ø¨Ø±', 'algebra', 'analyse', 'probabilitÃ©']):
        return 'Mathematiques'
    elif any(word in module_lower for word in ['ÙÙŠØ²ÙŠØ§Ø¡', 'physics', 'physique', 'mÃ©canique', 'thermodynamique']):
        return 'Physique'
    
    # Sciences de l'ingÃ©nieur
    elif any(word in module_lower for word in ['ÙƒÙ‡Ø±Ø¨Ø§Ø¦ÙŠØ©', 'electrical', 'Ã©lectrique', 'Ø¯Ø§Ø±Ø§Øª', 'circuits']):
        return 'Electrique'
    elif any(word in module_lower for word in ['Ø§Ù„ÙƒØªØ±ÙˆÙ†', 'electron', 'Ã©lectronique']):
        return 'Electronique'
    elif any(word in module_lower for word in ['Ù…ÙŠÙƒØ§Ù†ÙŠÙƒ', 'mechanical', 'mÃ©canique', 'rdm']):
        return 'Mecanique'
    elif any(word in module_lower for word in ['ØªØ­ÙƒÙ…', 'control', 'automatique', 'rÃ©gulation']):
        return 'Automatique'
    
    # Informatique
    elif any(word in module_lower for word in ['Ø¨Ø±Ù…Ø¬', 'program', 'Ø­Ø§Ø³ÙˆØ¨', 'computer', 'informatique', 'algorithme']):
        return 'Informatique'
    
    # Langues et communication
    elif any(word in module_lower for word in ['Ø§Ù†ÙƒÙ„ÙŠØ²ÙŠØ©', 'english', 'Ù„ØºØ©', 'franÃ§ais', 'communication', 'tec']):
        return 'Langues_Communication'
    
    # Gestion et Ã©conomie
    elif any(word in module_lower for word in ['Ø§Ù‚ØªØµØ§Ø¯', 'Ã©conomie', 'gestion', 'management', 'comptabilitÃ©']):
        return 'Gestion_Economie'
    
    else:
        return 'Autres'

df['pole_competence'] = df['Module'].apply(categoriser_module)

# Performance par pÃ´le de compÃ©tences
pole_perf = df.groupby(['ID', 'pole_competence'])['Note_sur_20'].mean().unstack(fill_value=0)
pole_perf = pole_perf.add_prefix('force_')
pole_perf = pole_perf.reset_index()

df = df.merge(pole_perf, on='ID', how='left')

# 3.10 Indicateurs spÃ©cifiques au systÃ¨me marocain
print("ğŸ“ˆ 3.10 Indicateurs spÃ©cifiques au systÃ¨me LMD marocain...")

# Nombre de modules en rattrapage potentiel
df['modules_rattrapage'] = df.groupby('ID')['Needs_Support'].transform('sum')

# Distance au seuil de validation
df['distance_seuil'] = df['Note_sur_20'] - SEUIL_VALIDATION

print(f"\nâœ… Feature Engineering terminÃ©!")
print(f"   â€¢ Nombre de features crÃ©Ã©es: {len([c for c in df.columns if c not in ['index', 'ID', 'Module', 'Status', 'AnneUniversitaire', 'Filiere']])}")

# =============================================================================
# 4. PRÃ‰PARATION DES DONNÃ‰ES POUR LA MODÃ‰LISATION
# =============================================================================
print("\n" + "=" * 80)
print("ğŸ”§ Ã‰TAPE 4: PRÃ‰PARATION POUR LA MODÃ‰LISATION")
print("=" * 80)

# SÃ©lectionner les features pour le modÃ¨le
feature_columns = [
    'Practical', 'Theoretical', 'Total', 'Note_sur_20', 'Semester', 'Annee',
    'peer_group_avg_total', 'peer_group_avg_note20', 'peer_group_avg_practical', 'peer_group_support_rate',
    'deviation_from_peer', 'deviation_note20', 'student_avg_total', 'student_std_total',
    'student_min_total', 'student_max_total', 'student_module_count',
    'student_avg_note20', 'student_min_note20',
    'student_avg_practical', 'student_avg_theoretical', 'student_support_rate',
    'module_avg_total', 'module_avg_note20', 'module_taux_echec', 'module_effectif',
    'combo_taux_echec', 'combo_haut_risque', 'charge_semestre',
    'taux_absenteisme', 'ratio_pratique', 'ecart_theorie_pratique',
    'modules_rattrapage', 'distance_seuil'
]

# Ajouter les colonnes de force par pÃ´le de compÃ©tences
force_cols = [c for c in df.columns if c.startswith('force_')]
feature_columns.extend(force_cols)

# Encoder les variables catÃ©gorielles
le_filiere = LabelEncoder()
df['Filiere_encoded'] = le_filiere.fit_transform(df['Filiere'].fillna('Inconnue'))
feature_columns.append('Filiere_encoded')

# Encoder le pÃ´le de compÃ©tences
le_pole = LabelEncoder()
df['pole_encoded'] = le_pole.fit_transform(df['pole_competence'].fillna('Autres'))
feature_columns.append('pole_encoded')

# CrÃ©er le DataFrame de features (garder seulement les colonnes existantes)
available_features = [c for c in feature_columns if c in df.columns]
X = df[available_features].copy()
y = df['Needs_Support']

# Remplir les valeurs manquantes
X = X.fillna(0)

# Remplacer les infinis
X = X.replace([np.inf, -np.inf], 0)

print(f"\nğŸ“Š Dimensions des donnÃ©es:")
print(f"   â€¢ Features (X): {X.shape}")
print(f"   â€¢ Target (y): {y.shape}")
print(f"   â€¢ Features sÃ©lectionnÃ©es: {len(available_features)}")
print(f"   â€¢ FiliÃ¨res: {df['Filiere'].nunique()}")

# Mise Ã  jour de feature_columns pour utiliser les features disponibles
feature_columns = available_features

# Split des donnÃ©es
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

print(f"\nğŸ“Š Split Train/Test:")
print(f"   â€¢ Training: {len(X_train):,} Ã©chantillons")
print(f"   â€¢ Test: {len(X_test):,} Ã©chantillons")

# Standardisation
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# =============================================================================
# 5. CLUSTERING DES Ã‰TUDIANTS (Profils d'Apprenants)
# =============================================================================
print("\n" + "=" * 80)
print("ğŸ”· Ã‰TAPE 5: CLUSTERING DES PROFILS D'APPRENANTS")
print("=" * 80)

# Clustering sur les profils Ã©tudiants
print("\nğŸ“Š Identification des profils d'apprenants par K-Means...")

# DÃ©terminer le nombre optimal de clusters avec l'inertie
inertias = []
K_range = range(2, 10)
for k in K_range:
    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
    kmeans.fit(X_train_scaled)
    inertias.append(kmeans.inertia_)

# Utiliser K=5 clusters (profils types d'Ã©tudiants marocains)
n_clusters = 5
kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
cluster_labels_train = kmeans.fit_predict(X_train_scaled)
cluster_labels_test = kmeans.predict(X_test_scaled)

# Nommer les clusters selon les profils
profil_names = {
    0: "Excellence",
    1: "RÃ©gulier", 
    2: "En_Progression",
    3: "En_DifficultÃ©",
    4: "Ã€_Risque"
}

# Analyser les clusters
print(f"\nğŸ“Š Analyse des {n_clusters} profils d'apprenants:")
cluster_analysis = []
for i in range(n_clusters):
    mask = cluster_labels_train == i
    support_rate = y_train.iloc[mask].mean() * 100
    size = mask.sum()
    cluster_analysis.append((i, size, support_rate))

# Trier par taux de soutien pour attribuer les noms
cluster_analysis.sort(key=lambda x: x[2])
profil_mapping = {}
profil_labels = ["Excellence", "RÃ©gulier", "En_Progression", "En_DifficultÃ©", "Ã€_Risque"]
for idx, (cluster_id, size, rate) in enumerate(cluster_analysis):
    profil_mapping[cluster_id] = profil_labels[idx]
    print(f"   â€¢ Profil '{profil_labels[idx]}' (Cluster {cluster_id}): {size:,} Ã©tudiants, Taux de soutien: {rate:.1f}%")

# Visualisation des clusters
fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# Elbow curve
axes[0].plot(K_range, inertias, 'bo-', linewidth=2, markersize=8)
axes[0].set_xlabel('Nombre de Profils (K)', fontsize=12)
axes[0].set_ylabel('Inertie', fontsize=12)
axes[0].set_title('MÃ©thode du Coude - SÃ©lection du Nombre de Profils', fontsize=14, fontweight='bold')
axes[0].axvline(x=n_clusters, color='r', linestyle='--', label=f'K choisi = {n_clusters}')
axes[0].legend()
axes[0].grid(True, alpha=0.3)

# Cluster distribution avec noms de profils
cluster_support = pd.DataFrame({
    'Cluster': cluster_labels_train,
    'Needs_Support': y_train.values
})
cluster_summary = cluster_support.groupby('Cluster')['Needs_Support'].agg(['sum', 'count', 'mean'])
cluster_summary['mean'] = cluster_summary['mean'] * 100

colors = plt.cm.RdYlGn_r(cluster_summary['mean'] / 100)
bars = axes[1].bar(range(len(cluster_summary)), cluster_summary['mean'], color=colors, edgecolor='black')
axes[1].set_xticks(range(len(cluster_summary)))
axes[1].set_xticklabels([profil_mapping.get(i, f'Profil {i}') for i in cluster_summary.index], rotation=45, ha='right')
axes[1].set_xlabel('Profil d\'Apprenant', fontsize=12)
axes[1].set_ylabel('Taux de Besoin de Soutien (%)', fontsize=12)
axes[1].set_title('Taux de Soutien par Profil d\'Apprenant', fontsize=14, fontweight='bold')
axes[1].axhline(y=50, color='r', linestyle='--', alpha=0.7, label='Seuil 50%')
for bar, (idx, row) in zip(bars, cluster_summary.iterrows()):
    axes[1].annotate(f'n={int(row["count"])}', xy=(bar.get_x() + bar.get_width()/2, bar.get_height()),
                     ha='center', va='bottom', fontsize=10)
axes[1].legend()
axes[1].grid(True, alpha=0.3, axis='y')

plt.tight_layout()
plt.savefig(OUTPUT_PATH / 'profils_apprenants.png', dpi=300, bbox_inches='tight')
plt.close()
print(f"\nâœ… Visualisation des profils sauvegardÃ©e: profils_apprenants.png")

# =============================================================================
# 6. COLLABORATIVE FILTERING (SimilaritÃ© entre Ã‰tudiants Marocains)
# =============================================================================
print("\n" + "=" * 80)
print("ğŸ¤ Ã‰TAPE 6: SYSTÃˆME DE RECOMMANDATION COLLABORATIF")
print("=" * 80)

print("\nğŸ“Š Construction du systÃ¨me de recommandation basÃ© sur la similaritÃ©...")

# CrÃ©er une matrice Ã©tudiant-module pour le collaborative filtering
student_module_matrix = df.pivot_table(
    index='ID', 
    columns='Module', 
    values='Note_sur_20', 
    aggfunc='mean'
).fillna(0)

print(f"   â€¢ Matrice Ã‰tudiant-Module: {student_module_matrix.shape}")
print(f"   â€¢ Ã‰tudiants: {student_module_matrix.shape[0]}")
print(f"   â€¢ Modules: {student_module_matrix.shape[1]}")

# Trouver les voisins les plus proches (Ã©tudiants similaires)
n_neighbors = min(10, len(student_module_matrix) - 1)
nn_model = NearestNeighbors(n_neighbors=n_neighbors, metric='cosine')
nn_model.fit(student_module_matrix.values)

def recommander_soutien(student_id, student_matrix, nn_model, df):
    """
    Recommande des modules nÃ©cessitant du soutien basÃ© sur des Ã©tudiants 
    au profil similaire (systÃ¨me de recommandation collaboratif).
    
    Logique: Si des Ã©tudiants similaires ont eu des difficultÃ©s dans certains
    modules, l'Ã©tudiant actuel risque aussi d'avoir des difficultÃ©s.
    """
    if student_id not in student_matrix.index:
        return {}
    
    student_vec = student_matrix.loc[student_id].values.reshape(1, -1)
    distances, indices = nn_model.kneighbors(student_vec)
    
    # Ã‰tudiants similaires (exclure l'Ã©tudiant lui-mÃªme)
    similar_students = student_matrix.index[indices[0][1:]]
    
    # Modules problÃ©matiques chez les Ã©tudiants similaires
    similar_df = df[df['ID'].isin(similar_students)]
    modules_risque = similar_df[similar_df['Needs_Support'] == 1]['Module'].value_counts()
    
    return modules_risque.head(5).to_dict()

# Exemples de recommandations
sample_students = df['ID'].unique()[:3]
print("\nğŸ“‹ Exemples de recommandations pour Ã©tudiants:")
for student in sample_students:
    recommendations = recommander_soutien(student, student_module_matrix, nn_model, df)
    if recommendations:
        filiere = df[df['ID'] == student]['Filiere'].iloc[0] if len(df[df['ID'] == student]) > 0 else 'Inconnue'
        print(f"\n   ğŸ“ Ã‰tudiant {student} (FiliÃ¨re: {filiere}):")
        print(f"      Modules Ã  surveiller (basÃ© sur Ã©tudiants similaires):")
        for module, count in list(recommendations.items())[:3]:
            module_display = module[:50] + '...' if len(str(module)) > 50 else module
            print(f"      â€¢ {module_display}: {count} Ã©tudiants similaires en difficultÃ©")

# =============================================================================
# 7. MODÃˆLE XGBOOST AVEC CALIBRATION (PrÃ©diction du Besoin de Soutien)
# =============================================================================
print("\n" + "=" * 80)
print("ğŸš€ Ã‰TAPE 7: MODÃˆLE DE PRÃ‰DICTION XGBOOST")
print("=" * 80)

# EntraÃ®ner XGBoost
print("\nğŸ“Š EntraÃ®nement du modÃ¨le XGBoost pour prÃ©dire le besoin de soutien...")

xgb_model = xgb.XGBClassifier(
    n_estimators=200,
    max_depth=6,
    learning_rate=0.1,
    subsample=0.8,
    colsample_bytree=0.8,
    random_state=42,
    use_label_encoder=False,
    eval_metric='logloss'
)

xgb_model.fit(X_train_scaled, y_train)

# Calibration des probabilitÃ©s pour des scores de risque fiables
print("ğŸ“Š Calibration des probabilitÃ©s pour scoring de risque...")
calibrated_model = CalibratedClassifierCV(xgb_model, method='sigmoid', cv=5)
calibrated_model.fit(X_train_scaled, y_train)

# PrÃ©dictions
y_pred = calibrated_model.predict(X_test_scaled)
y_proba = calibrated_model.predict_proba(X_test_scaled)[:, 1]

# Ã‰valuation
print("\nğŸ“Š RÃ‰SULTATS DU MODÃˆLE DE PRÃ‰DICTION:")
print("-" * 50)
print(classification_report(y_test, y_pred, target_names=['ValidÃ©', 'Besoin_Soutien']))

# MÃ©triques supplÃ©mentaires
roc_auc = roc_auc_score(y_test, y_proba)
avg_precision = average_precision_score(y_test, y_proba)
f1 = f1_score(y_test, y_pred)

print(f"\nğŸ“ˆ MÃ©triques de Performance:")
print(f"   â€¢ ROC-AUC Score: {roc_auc:.4f}")
print(f"   â€¢ Average Precision: {avg_precision:.4f}")
print(f"   â€¢ F1-Score: {f1:.4f}")

# Cross-validation
print("\nğŸ“Š Validation croisÃ©e (5-fold)...")
cv_scores = cross_val_score(xgb_model, X_train_scaled, y_train, cv=5, scoring='roc_auc')
print(f"   â€¢ ROC-AUC moyen: {cv_scores.mean():.4f} (+/- {cv_scores.std()*2:.4f})")

# =============================================================================
# 7.1 SAUVEGARDE DU MODÃˆLE POUR PRÃ‰DICTIONS EXTERNES
# =============================================================================
print("\nğŸ’¾ Sauvegarde du modÃ¨le pour prÃ©dictions futures...")
import joblib

# Sauvegarder le modÃ¨le calibrÃ©, le scaler, et les mÃ©tadonnÃ©es
model_data = {
    'model': calibrated_model,
    'xgb_model': xgb_model,
    'scaler': scaler,
    'feature_columns': feature_columns,
    'le_filiere': le_filiere,
    'le_pole': le_pole,
    'kmeans': kmeans,
    'profil_mapping': profil_mapping,
    'seuil_validation': SEUIL_VALIDATION
}

joblib.dump(model_data, OUTPUT_PATH / 'model_soutien_pedagogique.joblib')
print(f"   âœ… ModÃ¨le sauvegardÃ©: model_soutien_pedagogique.joblib")

# =============================================================================
# 8. IMPORTANCE DES FACTEURS DE RISQUE
# =============================================================================
print("\n" + "=" * 80)
print("ğŸ“Š Ã‰TAPE 8: FACTEURS DE RISQUE LES PLUS IMPORTANTS")
print("=" * 80)

# Feature importance
feature_importance = pd.DataFrame({
    'facteur': feature_columns,
    'importance': xgb_model.feature_importances_
}).sort_values('importance', ascending=False)

# Renommer les features pour le contexte marocain
feature_names_ma = {
    'student_support_rate': 'Historique_Echecs_Etudiant',
    'module_taux_echec': 'DifficultÃ©_Module',
    'taux_absenteisme': 'Taux_AbsentÃ©isme',
    'deviation_from_peer': 'Ã‰cart_Promotion',
    'student_avg_note20': 'Moyenne_GÃ©nÃ©rale_Ã‰tudiant',
    'combo_taux_echec': 'Risque_FiliÃ¨re_Module',
    'distance_seuil': 'Distance_Seuil_Validation',
    'Note_sur_20': 'Note_Module',
    'charge_semestre': 'Charge_Semestre',
    'Annee': 'AnnÃ©e_Ã‰tudes'
}

feature_importance['facteur_ma'] = feature_importance['facteur'].map(
    lambda x: feature_names_ma.get(x, x)
)

print("\nğŸ” Top 15 Facteurs de Risque les plus importants:")
for i, row in feature_importance.head(15).iterrows():
    rank = list(feature_importance.index).index(i) + 1
    print(f"   {rank:2d}. {row['facteur_ma']}: {row['importance']:.4f}")

# Visualisation
fig, axes = plt.subplots(1, 2, figsize=(16, 6))

# Feature importance
top_features = feature_importance.head(15)
colors = plt.cm.viridis(np.linspace(0.3, 0.9, len(top_features)))
bars = axes[0].barh(range(len(top_features)), top_features['importance'].values, color=colors)
axes[0].set_yticks(range(len(top_features)))
axes[0].set_yticklabels(top_features['facteur_ma'].values)
axes[0].invert_yaxis()
axes[0].set_xlabel('Importance', fontsize=12)
axes[0].set_title('Top 15 Facteurs de Risque - Importance XGBoost', fontsize=14, fontweight='bold')
axes[0].grid(True, alpha=0.3, axis='x')

# Confusion Matrix avec labels marocains
cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[1],
            xticklabels=['ValidÃ©', 'Besoin Soutien'],
            yticklabels=['ValidÃ©', 'Besoin Soutien'])
axes[1].set_xlabel('PrÃ©dit', fontsize=12)
axes[1].set_ylabel('RÃ©el', fontsize=12)
axes[1].set_title('Matrice de Confusion', fontsize=14, fontweight='bold')

plt.tight_layout()
plt.savefig(OUTPUT_PATH / 'performance_modele.png', dpi=300, bbox_inches='tight')
plt.close()
print(f"\nâœ… Visualisation performance sauvegardÃ©e: performance_modele.png")

# =============================================================================
# 9. SYSTÃˆME DE SCORING DE RISQUE (Priorisation Marocaine)
# =============================================================================
print("\n" + "=" * 80)
print("âš ï¸ Ã‰TAPE 9: SYSTÃˆME DE SCORING ET PRIORISATION")
print("=" * 80)

# Ajouter les scores de risque au dataset
df_test = df.iloc[X_test.index].copy()
df_test['score_risque'] = y_proba
df_test['cluster'] = cluster_labels_test
df_test['profil_apprenant'] = df_test['cluster'].map(profil_mapping)
df_test['besoin_soutien_predit'] = y_pred

# CatÃ©goriser les risques selon le systÃ¨me marocain
def categorie_risque(score):
    """
    CatÃ©gorisation du risque adaptÃ©e au contexte universitaire marocain:
    - CRITIQUE: Risque trÃ¨s Ã©levÃ© de non-validation / redoublement
    - Ã‰LEVÃ‰: NÃ©cessite intervention urgente
    - MODÃ‰RÃ‰: Suivi recommandÃ©
    - FAIBLE: Accompagnement lÃ©ger
    - MINIMAL: Pas d'intervention nÃ©cessaire
    """
    if score >= 0.8:
        return 'CRITIQUE'
    elif score >= 0.6:
        return 'Ã‰LEVÃ‰'
    elif score >= 0.4:
        return 'MODÃ‰RÃ‰'
    elif score >= 0.2:
        return 'FAIBLE'
    else:
        return 'MINIMAL'

df_test['categorie_risque'] = df_test['score_risque'].apply(categorie_risque)

# Recommandation d'action
def recommander_action(cat_risque, note):
    if cat_risque == 'CRITIQUE':
        return "Tutorat individuel + Convocation conseiller pÃ©dagogique"
    elif cat_risque == 'Ã‰LEVÃ‰':
        return "Inscription TD de soutien + Suivi bi-hebdomadaire"
    elif cat_risque == 'MODÃ‰RÃ‰':
        return "Groupes d'entraide + Ressources en ligne"
    elif cat_risque == 'FAIBLE':
        return "Auto-Ã©valuation + Permanences optionnelles"
    else:
        return "Encouragement + Ressources avancÃ©es"

df_test['action_recommandee'] = df_test.apply(
    lambda row: recommander_action(row['categorie_risque'], row['Note_sur_20']), axis=1
)

print("\nğŸ“Š Distribution des catÃ©gories de risque:")
risk_dist = df_test['categorie_risque'].value_counts()
for cat in ['CRITIQUE', 'Ã‰LEVÃ‰', 'MODÃ‰RÃ‰', 'FAIBLE', 'MINIMAL']:
    if cat in risk_dist.index:
        count = risk_dist[cat]
        pct = count / len(df_test) * 100
        emoji = {'CRITIQUE': 'ğŸ”´', 'Ã‰LEVÃ‰': 'ğŸŸ ', 'MODÃ‰RÃ‰': 'ğŸŸ¡', 'FAIBLE': 'ğŸŸ¢', 'MINIMAL': 'âšª'}
        print(f"   {emoji.get(cat, 'â€¢')} {cat}: {count:,} Ã©tudiants ({pct:.1f}%)")

# =============================================================================
# 10. ANALYSE DES COMBINAISONS FILIÃˆRE-MODULE Ã€ HAUT RISQUE
# =============================================================================
print("\n" + "=" * 80)
print("ğŸ”´ Ã‰TAPE 10: COMBINAISONS FILIÃˆRE-MODULE Ã€ SURVEILLER")
print("=" * 80)

high_risk_combos = df.groupby(['Filiere', 'Module']).agg({
    'Needs_Support': ['mean', 'sum', 'count'],
    'Note_sur_20': 'mean'
}).reset_index()
high_risk_combos.columns = ['Filiere', 'Module', 'taux_echec', 'nb_echecs', 'effectif', 'moyenne_module']
high_risk_combos = high_risk_combos[high_risk_combos['effectif'] >= 10]  # Au moins 10 Ã©tudiants
high_risk_combos = high_risk_combos.sort_values('taux_echec', ascending=False)

print("\nğŸ”´ Combinaisons FiliÃ¨re-Module avec taux d'Ã©chec > 50%:")
print("-" * 90)
high_risk_top = high_risk_combos[high_risk_combos['taux_echec'] > 0.5].head(15)
for i, row in high_risk_top.iterrows():
    module_display = row['Module'][:35] + '...' if len(str(row['Module'])) > 35 else row['Module']
    print(f"   ğŸ“š {row['Filiere']} - {module_display}")
    print(f"      Taux Ã©chec: {row['taux_echec']*100:.1f}% | Ã‰checs: {int(row['nb_echecs'])}/{int(row['effectif'])} | Moy: {row['moyenne_module']:.1f}/20")

# Visualisation des risques
fig, axes = plt.subplots(1, 2, figsize=(16, 6))

# Distribution des catÃ©gories de risque
risk_order = ['MINIMAL', 'FAIBLE', 'MODÃ‰RÃ‰', 'Ã‰LEVÃ‰', 'CRITIQUE']
risk_counts = df_test['categorie_risque'].value_counts().reindex(risk_order).fillna(0)
colors = ['#27ae60', '#f1c40f', '#e67e22', '#e74c3c', '#8e44ad']
axes[0].bar(risk_counts.index, risk_counts.values, color=colors, edgecolor='black')
axes[0].set_xlabel('CatÃ©gorie de Risque', fontsize=12)
axes[0].set_ylabel('Nombre d\'Ã‰tudiants', fontsize=12)
axes[0].set_title('Distribution des Niveaux de Risque\n(SystÃ¨me Universitaire Marocain)', fontsize=14, fontweight='bold')
for i, v in enumerate(risk_counts.values):
    axes[0].annotate(f'{int(v):,}', xy=(i, v), ha='center', va='bottom', fontsize=11)
axes[0].grid(True, alpha=0.3, axis='y')

# Distribution des scores de risque
axes[1].hist(y_proba[y_test == 0], bins=50, alpha=0.7, label='ValidÃ©', color='green', density=True)
axes[1].hist(y_proba[y_test == 1], bins=50, alpha=0.7, label='Besoin Soutien', color='red', density=True)
axes[1].axvline(x=0.5, color='black', linestyle='--', label='Seuil 0.5')
axes[1].axvline(x=0.8, color='purple', linestyle='--', alpha=0.7, label='Seuil Critique')
axes[1].set_xlabel('Score de Risque', fontsize=12)
axes[1].set_ylabel('DensitÃ©', fontsize=12)
axes[1].set_title('Distribution des Scores de Risque', fontsize=14, fontweight='bold')
axes[1].legend()
axes[1].grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig(OUTPUT_PATH / 'analyse_risques.png', dpi=300, bbox_inches='tight')
plt.close()
print(f"\nâœ… Visualisation risques sauvegardÃ©e: analyse_risques.png")

# =============================================================================
# 11. RECOMMANDATIONS D'ALLOCATION DES RESSOURCES DE SOUTIEN
# =============================================================================
print("\n" + "=" * 80)
print("ğŸ‘¨â€ğŸ« Ã‰TAPE 11: PLAN D'ALLOCATION DES RESSOURCES DE SOUTIEN")
print("=" * 80)

# PrioritÃ© par module
module_priority = df_test[df_test['categorie_risque'].isin(['CRITIQUE', 'Ã‰LEVÃ‰'])].groupby('Module').agg({
    'score_risque': 'mean',
    'ID': 'count',
    'Note_sur_20': 'mean'
}).reset_index()
module_priority.columns = ['Module', 'score_risque_moy', 'nb_etudiants', 'moyenne_module']
module_priority = module_priority.sort_values('score_risque_moy', ascending=False)

print("\nğŸ“‹ MODULES PRIORITAIRES POUR LE TUTORAT (TD de Soutien):")
print("-" * 90)
print(f"{'Rang':<5} {'Module':<40} {'Score Risque':<15} {'Ã‰tudiants':<12} {'Moyenne':<10}")
print("-" * 90)
for i, row in module_priority.head(10).iterrows():
    rank = list(module_priority.index).index(i) + 1
    module_name = row['Module'][:37] + '...' if len(str(row['Module'])) > 40 else row['Module']
    print(f"{rank:<5} {module_name:<40} {row['score_risque_moy']:.3f}          {int(row['nb_etudiants']):<12} {row['moyenne_module']:.1f}/20")

# Recommandations par profil d'apprenant
print("\nğŸ“‹ STRATÃ‰GIE DE SOUTIEN PAR PROFIL D'APPRENANT:")
print("-" * 70)

strategies_ma = {
    'Ã€_Risque': """ğŸ”´ INTERVENTION URGENTE
      â€¢ Convocation par le conseiller pÃ©dagogique
      â€¢ Tutorat individuel (2h/semaine minimum)
      â€¢ Contrat pÃ©dagogique personnalisÃ©
      â€¢ Suivi psychologique si nÃ©cessaire
      â€¢ Orientation vers les permanences de soutien""",
    
    'En_DifficultÃ©': """ğŸŸ  SOUTIEN RENFORCÃ‰
      â€¢ Inscription obligatoire aux TD de soutien
      â€¢ Groupes de travail dirigÃ©s
      â€¢ Exercices de rattrapage hebdomadaires
      â€¢ Suivi bi-hebdomadaire par le tuteur
      â€¢ AccÃ¨s prioritaire aux ressources numÃ©riques""",
    
    'En_Progression': """ğŸŸ¡ ACCOMPAGNEMENT MODÃ‰RÃ‰
      â€¢ Sessions de rÃ©vision optionnelles
      â€¢ Groupes d'entraide entre Ã©tudiants
      â€¢ Auto-Ã©valuation rÃ©guliÃ¨re
      â€¢ Permanences des enseignants""",
    
    'RÃ©gulier': """ğŸŸ¢ CONSOLIDATION
      â€¢ Ressources en ligne complÃ©mentaires
      â€¢ PrÃ©paration aux examens
      â€¢ Encouragement Ã  l'excellence""",
    
    'Excellence': """â­ ENCOURAGEMENT
      â€¢ Programmes d'excellence
      â€¢ Tutorat par les pairs (comme tuteur)
      â€¢ Projets avancÃ©s
      â€¢ PrÃ©paration concours et bourses"""
}

for profil in ['Ã€_Risque', 'En_DifficultÃ©', 'En_Progression', 'RÃ©gulier', 'Excellence']:
    if profil in df_test['profil_apprenant'].values:
        profil_data = df_test[df_test['profil_apprenant'] == profil]
        size = len(profil_data)
        moy = profil_data['Note_sur_20'].mean()
        print(f"\n{profil.upper()} ({size} Ã©tudiants, moyenne: {moy:.1f}/20):")
        if profil in strategies_ma:
            print(strategies_ma[profil])

# =============================================================================
# 12. EXPORT DES RÃ‰SULTATS
# =============================================================================
print("\n" + "=" * 80)
print("ğŸ’¾ Ã‰TAPE 12: EXPORT DES RÃ‰SULTATS")
print("=" * 80)

# Export des Ã©tudiants Ã  risque Ã©levÃ©
etudiants_risque = df_test[df_test['categorie_risque'].isin(['CRITIQUE', 'Ã‰LEVÃ‰'])][
    ['ID', 'Filiere', 'Module', 'Note_sur_20', 'Statut_MA', 'score_risque', 
     'categorie_risque', 'profil_apprenant', 'action_recommandee']
].sort_values('score_risque', ascending=False)

etudiants_risque.to_csv(OUTPUT_PATH / 'etudiants_risque_eleve.csv', index=False, encoding='utf-8-sig')
print(f"\nâœ… Liste Ã©tudiants Ã  haut risque: etudiants_risque_eleve.csv ({len(etudiants_risque):,} enregistrements)")

# Export des recommandations par module
recommandations_modules = module_priority.copy()
recommandations_modules['rang_priorite'] = range(1, len(recommandations_modules) + 1)
recommandations_modules['tuteurs_recommandes'] = (recommandations_modules['nb_etudiants'] / 15).apply(lambda x: max(1, int(x)))
recommandations_modules['heures_td_soutien'] = recommandations_modules['tuteurs_recommandes'] * 2  # 2h par tuteur
recommandations_modules.to_csv(OUTPUT_PATH / 'recommandations_modules.csv', index=False, encoding='utf-8-sig')
print(f"âœ… Recommandations par module: recommandations_modules.csv")

# Export du scoring complet
scoring_complet = df_test[['ID', 'Filiere', 'Module', 'Annee', 'Semester', 'Note_sur_20', 
                           'Statut_MA', 'Mention', 'score_risque', 'categorie_risque', 
                           'profil_apprenant', 'action_recommandee', 'besoin_soutien_predit']].copy()
scoring_complet.to_csv(OUTPUT_PATH / 'scoring_complet.csv', index=False, encoding='utf-8-sig')
print(f"âœ… Scoring complet: scoring_complet.csv ({len(scoring_complet):,} enregistrements)")

# Export des combinaisons filiÃ¨re-module Ã  risque
high_risk_combos.to_csv(OUTPUT_PATH / 'combinaisons_risque.csv', index=False, encoding='utf-8-sig')
print(f"âœ… Combinaisons Ã  risque: combinaisons_risque.csv")

# Export du plan d'action par filiÃ¨re
plan_filiere = df_test.groupby('Filiere').agg({
    'score_risque': 'mean',
    'Needs_Support': 'sum',
    'ID': 'count',
    'Note_sur_20': 'mean'
}).reset_index()
plan_filiere.columns = ['Filiere', 'score_risque_moy', 'etudiants_en_difficulte', 'effectif_total', 'moyenne_filiere']
plan_filiere['taux_difficulte'] = plan_filiere['etudiants_en_difficulte'] / plan_filiere['effectif_total'] * 100
plan_filiere = plan_filiere.sort_values('score_risque_moy', ascending=False)
plan_filiere.to_csv(OUTPUT_PATH / 'plan_action_filieres.csv', index=False, encoding='utf-8-sig')
print(f"âœ… Plan d'action par filiÃ¨re: plan_action_filieres.csv")

# =============================================================================
# 13. TABLEAU DE BORD RÃ‰CAPITULATIF
# =============================================================================
print("\n" + "=" * 80)
print("ğŸ“Š TABLEAU DE BORD RÃ‰CAPITULATIF")
print("=" * 80)

fig = plt.figure(figsize=(20, 14))

# 1. Distribution des risques (pie chart)
ax1 = fig.add_subplot(2, 3, 1)
risk_counts = df_test['categorie_risque'].value_counts()
colors_pie = {'MINIMAL': '#27ae60', 'FAIBLE': '#f1c40f', 'MODÃ‰RÃ‰': '#e67e22', 'Ã‰LEVÃ‰': '#e74c3c', 'CRITIQUE': '#8e44ad'}
ax1.pie(risk_counts.values, labels=risk_counts.index, autopct='%1.1f%%',
        colors=[colors_pie.get(x, 'gray') for x in risk_counts.index], startangle=90)
ax1.set_title('Distribution des Niveaux de Risque\n(UniversitÃ© Marocaine)', fontsize=12, fontweight='bold')

# 2. Performance par FiliÃ¨re
ax2 = fig.add_subplot(2, 3, 2)
filiere_perf = df.groupby('Filiere')['Needs_Support'].mean().sort_values(ascending=True)
colors_filiere = plt.cm.RdYlGn_r(filiere_perf.values)
bars = ax2.barh(filiere_perf.index, filiere_perf.values * 100, color=colors_filiere)
ax2.set_xlabel('Taux de Besoin de Soutien (%)')
ax2.set_title('Taux de Soutien par FiliÃ¨re', fontsize=12, fontweight='bold')
ax2.axvline(x=50, color='r', linestyle='--', alpha=0.7)

# 3. Ã‰volution par annÃ©e universitaire
ax3 = fig.add_subplot(2, 3, 3)
year_trend = df.groupby('AnneUniversitaire')['Needs_Support'].mean() * 100
ax3.plot(range(len(year_trend)), year_trend.values, 'bo-', linewidth=2, markersize=8)
ax3.set_xticks(range(len(year_trend)))
ax3.set_xticklabels(year_trend.index, rotation=45)
ax3.set_ylabel('Taux de Besoin de Soutien (%)')
ax3.set_title('Ã‰volution par AnnÃ©e Universitaire', fontsize=12, fontweight='bold')
ax3.grid(True, alpha=0.3)

# 4. Top 10 modules Ã  risque
ax4 = fig.add_subplot(2, 3, 4)
top_modules = df.groupby('Module')['Needs_Support'].mean().sort_values(ascending=False).head(10)
colors_mod = plt.cm.Reds(np.linspace(0.4, 0.9, len(top_modules)))
ax4.barh(range(len(top_modules)), top_modules.values * 100, color=colors_mod)
ax4.set_yticks(range(len(top_modules)))
ax4.set_yticklabels([s[:25] + '...' if len(str(s)) > 25 else s for s in top_modules.index], fontsize=9)
ax4.invert_yaxis()
ax4.set_xlabel('Taux de Besoin de Soutien (%)')
ax4.set_title('Top 10 Modules Ã  Risque', fontsize=12, fontweight='bold')

# 5. Analyse par Profil d'Apprenant
ax5 = fig.add_subplot(2, 3, 5)
profil_risk = df_test.groupby('profil_apprenant').agg({
    'score_risque': 'mean',
    'ID': 'count'
}).reset_index()
profil_colors = {'Excellence': '#27ae60', 'RÃ©gulier': '#3498db', 'En_Progression': '#f1c40f', 
                 'En_DifficultÃ©': '#e67e22', 'Ã€_Risque': '#e74c3c'}
bars = ax5.bar(profil_risk['profil_apprenant'], profil_risk['score_risque'],
               color=[profil_colors.get(p, 'gray') for p in profil_risk['profil_apprenant']], edgecolor='black')
ax5.set_xlabel('Profil d\'Apprenant')
ax5.set_ylabel('Score de Risque Moyen')
ax5.set_title('Risque par Profil d\'Apprenant', fontsize=12, fontweight='bold')
ax5.tick_params(axis='x', rotation=45)
for bar, (_, row) in zip(bars, profil_risk.iterrows()):
    ax5.annotate(f'n={int(row["ID"])}', xy=(bar.get_x() + bar.get_width()/2, bar.get_height()),
                 ha='center', va='bottom', fontsize=9)

# 6. MÃ©triques clÃ©s
ax6 = fig.add_subplot(2, 3, 6)
ax6.axis('off')
nb_critique = len(df_test[df_test['categorie_risque']=='CRITIQUE']) if 'CRITIQUE' in df_test['categorie_risque'].values else 0
nb_eleve = len(df_test[df_test['categorie_risque']=='Ã‰LEVÃ‰']) if 'Ã‰LEVÃ‰' in df_test['categorie_risque'].values else 0
nb_modules_surveiller = len(module_priority[module_priority['score_risque_moy'] > 0.5]) if len(module_priority) > 0 else 0
metrics_text = f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘    ğŸ‡²ğŸ‡¦ MÃ‰TRIQUES - SYSTÃˆME UNIVERSITAIRE MAROCAIN   â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  ğŸ“Š Total Ã‰tudiants AnalysÃ©s: {len(df):,}            
â•‘  ğŸ¯ ROC-AUC Score: {roc_auc:.4f}                     
â•‘  ğŸ“ˆ F1-Score: {f1:.4f}                               
â•‘  ğŸ” PrÃ©cision Moyenne: {avg_precision:.4f}           
â•‘                                                      
â•‘  âš ï¸ Ã‰tudiants Risque CRITIQUE: {nb_critique:,}
â•‘  ğŸ”´ Ã‰tudiants Risque Ã‰LEVÃ‰: {nb_eleve:,}
â•‘  ğŸ“š Modules Ã  Surveiller: {nb_modules_surveiller}
â•‘  ğŸ·ï¸ Profils IdentifiÃ©s: {n_clusters}               
â•‘                                                      
â•‘  ğŸ’¡ RECOMMANDATION:                                  
â•‘  Allouer {int((nb_critique + nb_eleve)/15)} tuteurs minimum
â•‘  Ouvrir {nb_modules_surveiller} TD de soutien                      
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""
ax6.text(0.05, 0.5, metrics_text, transform=ax6.transAxes, fontsize=10,
         verticalalignment='center', fontfamily='monospace',
         bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))

plt.suptitle('ğŸ”µ SystÃ¨me de Recommandation de Soutien PÃ©dagogique\nğŸ‡²ğŸ‡¦ AdaptÃ© pour les UniversitÃ©s Marocaines', 
             fontsize=16, fontweight='bold', y=1.02)
plt.tight_layout()
plt.savefig(OUTPUT_PATH / 'tableau_bord_soutien.png', dpi=300, bbox_inches='tight')
plt.close()
print(f"\nâœ… Tableau de bord sauvegardÃ©: tableau_bord_soutien.png")

# =============================================================================
# RÃ‰SUMÃ‰ FINAL
# =============================================================================
print("\n" + "=" * 80)
print("ğŸ¯ RÃ‰SUMÃ‰ FINAL - SYSTÃˆME DE SOUTIEN PÃ‰DAGOGIQUE MAROCAIN")
print("=" * 80)

nb_critique = len(df_test[df_test['categorie_risque']=='CRITIQUE']) if 'CRITIQUE' in df_test['categorie_risque'].values else 0
nb_eleve = len(df_test[df_test['categorie_risque']=='Ã‰LEVÃ‰']) if 'Ã‰LEVÃ‰' in df_test['categorie_risque'].values else 0

print(f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘      ğŸ‡²ğŸ‡¦ PROJET 4: SYSTÃˆME DE SOUTIEN - UNIVERSITÃ‰S MAROCAINES              â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                              â•‘
â•‘  ğŸ“Š DONNÃ‰ES ANALYSÃ‰ES:                                                       â•‘
â•‘     â€¢ {len(df):,} inscriptions Ã©tudiants                                     
â•‘     â€¢ {df['ID'].nunique():,} Ã©tudiants uniques                               
â•‘     â€¢ {df['Module'].nunique()} modules diffÃ©rents                            
â•‘     â€¢ {df['Filiere'].nunique()} filiÃ¨res                                     
â•‘                                                                              â•‘
â•‘  ğŸ¯ PERFORMANCE DU MODÃˆLE:                                                   â•‘
â•‘     â€¢ ROC-AUC: {roc_auc:.4f}                                                 
â•‘     â€¢ F1-Score: {f1:.4f}                                                     
â•‘     â€¢ PrÃ©cision Moyenne: {avg_precision:.4f}                                 
â•‘                                                                              â•‘
â•‘  âš ï¸ IDENTIFICATION DES BESOINS (Seuil validation: {SEUIL_VALIDATION}/20):   â•‘
â•‘     â€¢ Taux global de besoin de soutien: {df['Needs_Support'].mean()*100:.1f}%
â•‘     â€¢ Ã‰tudiants en situation CRITIQUE: {nb_critique:,}
â•‘     â€¢ Ã‰tudiants Ã  risque Ã‰LEVÃ‰: {nb_eleve:,}
â•‘                                                                              â•‘
â•‘  âœ… VALEUR AJOUTÃ‰E POUR L'UNIVERSITÃ‰:                                        â•‘
â•‘     â€¢ Identification prÃ©coce des Ã©tudiants Ã  risque de redoublement          â•‘
â•‘     â€¢ Allocation optimisÃ©e des TD de soutien par module                      â•‘
â•‘     â€¢ Priorisation des interventions avec scoring de risque                  â•‘
â•‘     â€¢ Profils d'apprenants pour stratÃ©gies pÃ©dagogiques ciblÃ©es              â•‘
â•‘     â€¢ SystÃ¨me de recommandation collaboratif                                 â•‘
â•‘                                                                              â•‘
â•‘  ğŸ’¾ FICHIERS GÃ‰NÃ‰RÃ‰S:                                                        â•‘
â•‘     â€¢ etudiants_risque_eleve.csv - Ã‰tudiants prioritaires                    â•‘
â•‘     â€¢ recommandations_modules.csv - Plan TD soutien par module               â•‘
â•‘     â€¢ scoring_complet.csv - Scoring de tous les Ã©tudiants                    â•‘
â•‘     â€¢ combinaisons_risque.csv - FiliÃ¨re-Module Ã  surveiller                  â•‘
â•‘     â€¢ plan_action_filieres.csv - Plan par filiÃ¨re                            â•‘
â•‘     â€¢ tableau_bord_soutien.png - Dashboard visuel                            â•‘
â•‘     â€¢ performance_modele.png - MÃ©triques du modÃ¨le                           â•‘
â•‘     â€¢ analyse_risques.png - Analyse des risques                              â•‘
â•‘     â€¢ profils_apprenants.png - Clustering des profils                        â•‘
â•‘                                                                              â•‘
â•‘  ğŸ“‹ ACTIONS RECOMMANDÃ‰ES:                                                    â•‘
â•‘     â€¢ Convoquer les {nb_critique} Ã©tudiants en situation critique            
â•‘     â€¢ Ouvrir TD de soutien pour les modules Ã  taux d'Ã©chec > 50%             â•‘
â•‘     â€¢ Affecter {int((nb_critique + nb_eleve)/15)} tuteurs minimum            
â•‘     â€¢ Mettre en place le suivi par profil d'apprenant                        â•‘
â•‘                                                                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
""")

print("\nâœ… Projet 4 terminÃ© avec succÃ¨s!")
print("ğŸ‡²ğŸ‡¦ SystÃ¨me adaptÃ© au contexte universitaire marocain")
print("=" * 80)
